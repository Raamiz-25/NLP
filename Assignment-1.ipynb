{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP ASSIGNMENT - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3Q. Find stem and lemma words for the given words?\n",
    "“cats\", \"trouble\", \"troubling\", \"troubled\", “having”, “Corriendo”, “at”, “was”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word : cats            Stemmed Word : cat             Lemma : cat\n",
      "Word : trouble         Stemmed Word : troubl          Lemma : trouble\n",
      "Word : troubling       Stemmed Word : troubl          Lemma : troubling\n",
      "Word : troubled        Stemmed Word : troubl          Lemma : troubled\n",
      "Word : having          Stemmed Word : have            Lemma : having\n",
      "Word : corriendo       Stemmed Word : corriendo       Lemma : corriendo\n",
      "Word : at              Stemmed Word : at              Lemma : at\n",
      "Word : was             Stemmed Word : wa              Lemma : wa\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "words = [\"cats\", \"trouble\", \"troubling\", \"troubled\", \"having\", \"corriendo\", \"at\", \"was\"]\n",
    "for word in words:\n",
    "    print(\"Word : %-*s Stemmed Word : %-*s Lemma : %s\" % (15,word,15,stemmer.stem(word),lemmatizer.lemmatize(word)), end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8Q.\tFind BoW for the given paragraph? And also find stem and lemma words?\n",
    "\n",
    "Text Summarization is one of those applications of Natural Language Processing (NLP) which is bound to have a huge impact on our lives. With growing digital media and ever-growing publishing – who has the time to go through entire articles / documents / books to decide whether they are useful or not? Thankfully – this technology is already here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Stem</th>\n",
       "      <th>Lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>already</td>\n",
       "      <td>1</td>\n",
       "      <td>alreadi</td>\n",
       "      <td>already</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>or</td>\n",
       "      <td>1</td>\n",
       "      <td>or</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>applications</td>\n",
       "      <td>1</td>\n",
       "      <td>applic</td>\n",
       "      <td>application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>useful</td>\n",
       "      <td>1</td>\n",
       "      <td>use</td>\n",
       "      <td>useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text</td>\n",
       "      <td>1</td>\n",
       "      <td>text</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>language</td>\n",
       "      <td>1</td>\n",
       "      <td>languag</td>\n",
       "      <td>language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>publishing</td>\n",
       "      <td>1</td>\n",
       "      <td>publish</td>\n",
       "      <td>publishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>technology</td>\n",
       "      <td>1</td>\n",
       "      <td>technolog</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>of</td>\n",
       "      <td>2</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>natural</td>\n",
       "      <td>1</td>\n",
       "      <td>natur</td>\n",
       "      <td>natural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>has</td>\n",
       "      <td>1</td>\n",
       "      <td>ha</td>\n",
       "      <td>ha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>media</td>\n",
       "      <td>1</td>\n",
       "      <td>media</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>they</td>\n",
       "      <td>1</td>\n",
       "      <td>they</td>\n",
       "      <td>they</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>processing</td>\n",
       "      <td>1</td>\n",
       "      <td>process</td>\n",
       "      <td>processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>to</td>\n",
       "      <td>3</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>digital</td>\n",
       "      <td>1</td>\n",
       "      <td>digit</td>\n",
       "      <td>digital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>and</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>go</td>\n",
       "      <td>1</td>\n",
       "      <td>go</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>here</td>\n",
       "      <td>1</td>\n",
       "      <td>here</td>\n",
       "      <td>here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>articles</td>\n",
       "      <td>1</td>\n",
       "      <td>articl</td>\n",
       "      <td>article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bound</td>\n",
       "      <td>1</td>\n",
       "      <td>bound</td>\n",
       "      <td>bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>growing</td>\n",
       "      <td>2</td>\n",
       "      <td>grow</td>\n",
       "      <td>growing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>huge</td>\n",
       "      <td>1</td>\n",
       "      <td>huge</td>\n",
       "      <td>huge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>through</td>\n",
       "      <td>1</td>\n",
       "      <td>through</td>\n",
       "      <td>through</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>nlp</td>\n",
       "      <td>1</td>\n",
       "      <td>nlp</td>\n",
       "      <td>nlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>lives</td>\n",
       "      <td>1</td>\n",
       "      <td>live</td>\n",
       "      <td>life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>this</td>\n",
       "      <td>1</td>\n",
       "      <td>thi</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>whether</td>\n",
       "      <td>1</td>\n",
       "      <td>whether</td>\n",
       "      <td>whether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>decide</td>\n",
       "      <td>1</td>\n",
       "      <td>decid</td>\n",
       "      <td>decide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>entire</td>\n",
       "      <td>1</td>\n",
       "      <td>entir</td>\n",
       "      <td>entire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>books</td>\n",
       "      <td>1</td>\n",
       "      <td>book</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>our</td>\n",
       "      <td>1</td>\n",
       "      <td>our</td>\n",
       "      <td>our</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>those</td>\n",
       "      <td>1</td>\n",
       "      <td>those</td>\n",
       "      <td>those</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>are</td>\n",
       "      <td>1</td>\n",
       "      <td>are</td>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>time</td>\n",
       "      <td>1</td>\n",
       "      <td>time</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>summarization</td>\n",
       "      <td>1</td>\n",
       "      <td>summar</td>\n",
       "      <td>summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>on</td>\n",
       "      <td>1</td>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>documents</td>\n",
       "      <td>1</td>\n",
       "      <td>document</td>\n",
       "      <td>document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>with</td>\n",
       "      <td>1</td>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>not</td>\n",
       "      <td>1</td>\n",
       "      <td>not</td>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>have</td>\n",
       "      <td>1</td>\n",
       "      <td>have</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>impact</td>\n",
       "      <td>1</td>\n",
       "      <td>impact</td>\n",
       "      <td>impact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ever</td>\n",
       "      <td>1</td>\n",
       "      <td>ever</td>\n",
       "      <td>ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>who</td>\n",
       "      <td>1</td>\n",
       "      <td>who</td>\n",
       "      <td>who</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>thankfully</td>\n",
       "      <td>1</td>\n",
       "      <td>thank</td>\n",
       "      <td>thankfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>which</td>\n",
       "      <td>1</td>\n",
       "      <td>which</td>\n",
       "      <td>which</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word Frequency       Stem          Lemma\n",
       "0         already         1    alreadi        already\n",
       "1              or         1         or             or\n",
       "2    applications         1     applic    application\n",
       "3          useful         1        use         useful\n",
       "4            text         1       text           text\n",
       "5        language         1    languag       language\n",
       "6      publishing         1    publish     publishing\n",
       "7      technology         1  technolog     technology\n",
       "8              of         2         of             of\n",
       "9         natural         1      natur        natural\n",
       "10            has         1         ha             ha\n",
       "11          media         1      media         medium\n",
       "12           they         1       they           they\n",
       "13     processing         1    process     processing\n",
       "14             to         3         to             to\n",
       "15        digital         1      digit        digital\n",
       "16            and         1        and            and\n",
       "17             go         1         go             go\n",
       "18           here         1       here           here\n",
       "19       articles         1     articl        article\n",
       "20          bound         1      bound          bound\n",
       "21        growing         2       grow        growing\n",
       "22           huge         1       huge           huge\n",
       "23        through         1    through        through\n",
       "24            nlp         1        nlp            nlp\n",
       "25          lives         1       live           life\n",
       "26           this         1        thi           this\n",
       "27        whether         1    whether        whether\n",
       "28         decide         1      decid         decide\n",
       "29         entire         1      entir         entire\n",
       "30          books         1       book           book\n",
       "31            our         1        our            our\n",
       "32          those         1      those          those\n",
       "33            are         1        are            are\n",
       "34           time         1       time           time\n",
       "35  summarization         1     summar  summarization\n",
       "36             on         1         on             on\n",
       "37      documents         1   document       document\n",
       "38           with         1       with           with\n",
       "39            not         1        not            not\n",
       "40           have         1       have           have\n",
       "41         impact         1     impact         impact\n",
       "42            one         1        one            one\n",
       "43           ever         1       ever           ever\n",
       "44            who         1        who            who\n",
       "45     thankfully         1      thank     thankfully\n",
       "46          which         1      which          which"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def word_extraction(sentence):\n",
    "    ignore = ['a', \"the\", \"is\"]\n",
    "    words = re.sub(\"[^\\w]\", \" \",  sentence).split()\n",
    "    cleaned_text = [w.lower() for w in words if w not in ignore]\n",
    "    return cleaned_text\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "txt = \"Text Summarization is one of those applications of Natural Language Processing (NLP) which is bound to have a huge impact on our lives. With growing digital media and ever-growing publishing – who has the time to go through entire articles / documents / books to decide whether they are useful or not? Thankfully – this technology is already here.\"\n",
    "txt = word_extraction(txt)\n",
    "data = pd.DataFrame(columns=['Word', 'Frequency', 'Stem', 'Lemma'])\n",
    "for word in set(txt):\n",
    "    data.loc[len(data.index)] = [word, txt.count(word), stemmer.stem(word), lemmatizer.lemmatize(word)]\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df13f10ace87b946fd57f957f4f2f2ab7ca87e3da9ec89264fcaface418ff5c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
